{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGN DCR Metric\n",
    "\n",
    "<br>**Author(s):** Weixiang Yu & Gordon Richards\n",
    "<br>**Last updated:** 08-10-20\n",
    "<br>**Short description:**\n",
    "This notebook build upon Peter Yoachim's `DcrPrecisionMetric` demonstrated [here](https://github.com/lsst/sims_maf/blob/master/python/lsst/sims/maf/metrics/dcrMetric.py). For some more context, you can also checkout this notebook ->[DCR_AGN_metric_analysis.ipynb](https://github.com/RichardsGroup/LSSTprep/blob/master/DCR/DCR_AGN_metric_analysis.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Software Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_username = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib to show plots inline.wfd_depth_scale0.95_v1.5_10yrs.db\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the sims_maf modules needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lsst.sim.maf moduels modules\n",
    "import lsst.sims.maf.db as db\n",
    "import lsst.sims.maf.metrics as metrics\n",
    "import lsst.sims.maf.slicers as slicers\n",
    "import lsst.sims.maf.stackers as stackers\n",
    "from lsst.sims.maf.stackers import BaseStacker\n",
    "import lsst.sims.maf.plots as plots\n",
    "import lsst.sims.maf.metricBundles as metricBundles\n",
    "\n",
    "# add opsimUtils module path to search\n",
    "import sys\n",
    "sys.path.insert(0, '../Scripts_NBs/')\n",
    "\n",
    "# import convenience functions\n",
    "from opsimUtils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idies/lsst/python/miniconda3-4.7.10/envs/lsst-scipipe-4d7b902/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:34814\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>16</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>257.77 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:34814' processes=16 cores=16>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dask and create client\n",
    "from dask.distributed import Client\n",
    "client = Client(n_workers=16)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.sims.maf.metrics import BaseMetric\n",
    "from lsst.sims.maf.utils.astrometryUtils import m52snr, astrom_precision\n",
    "\n",
    "class AGN_DCR(BaseMetric):\n",
    "    \"\"\"AGN DCR\"\"\"\n",
    "    \n",
    "    def __init__(self, band, src_mag=22, seeingCol='seeingFwhmGeom', m5Col='fiveSigmaDepth',\n",
    "                 PACol='paraAngle', filterCol='filter', atm_err=0.01, **kwargs):\n",
    "        \n",
    "        self.band = band # required\n",
    "        self.src_mag = src_mag\n",
    "        self.m5Col = m5Col\n",
    "        self.PACol = PACol\n",
    "        self.seeingCol = seeingCol\n",
    "        self.filterCol = filterCol\n",
    "        self.atm_err = 0.01\n",
    "        self.metricName = f'DCR_{src_mag}_{self.band}'\n",
    "        \n",
    "        cols=['airmass', self.filterCol, self.m5Col, self.PACol, self.seeingCol]\n",
    "        super(AGN_DCR, self).__init__(col=cols, metricName=self.metricName, **kwargs)\n",
    "        \n",
    "    def run(self, dataSlice, slicePoint=None):\n",
    "        \n",
    "        # get the data only corresponding the the desired filter\n",
    "        data_filt = dataSlice[np.where(dataSlice[self.filterCol] == self.band)]\n",
    "        \n",
    "        # compute snr and astrometric precision for given data slice\n",
    "        #GTR: Compute the SNR from the observed mag and limiting mag\n",
    "        #GTR: https://sims-maf.lsst.io/_modules/lsst/sims/maf/utils/astrometryUtils.html#m52snr\n",
    "        snr = m52snr(self.src_mag, data_filt[self.m5Col])\n",
    "        #GTR: The positional error is just the seeing scaled by the SNR with the error floor added in quadrature\n",
    "        #GTR: https://sims-maf.lsst.io/_modules/lsst/sims/maf/utils/astrometryUtils.html#astrom_precisio\n",
    "        pos_var = np.power(astrom_precision(data_filt[self.seeingCol], snr), 2) \\\n",
    "                  + self.atm_err**2\n",
    "        pos_err = np.sqrt(pos_var)\n",
    "        \n",
    "        # compute tan(Z), note that we might change sin(PA)\n",
    "        zenith = np.arccos(1/data_filt['airmass'])\n",
    "        x_coord = np.tan(zenith)*np.sin(np.radians(dataSlice[self.PACol]))\n",
    "        x_coord2 = np.tan(zenith)*np.cos(np.radians(dataSlice[self.PACol]))\n",
    "        # Things should be the same for RA and dec.\n",
    "        # Now I want to compute the error if I interpolate/extrapolate to +/-1.\n",
    "        \n",
    "        #GTR: Removing the PA term (and scale by 1/2) should have no effect.\n",
    "        #x_coord = np.tan(zenith)\n",
    "        #x_coord2 = np.tan(zenith)\n",
    "        \n",
    "\n",
    "        # function is of form, y=ax. a=y/x. da = dy/x.\n",
    "        # Only strictly true if we know the unshifted position. But this should be a reasonable approx.\n",
    "        slope_uncerts = pos_err/x_coord\n",
    "        slope_uncerts2 = pos_err/x_coord2\n",
    "\n",
    "        total_slope_uncert = 1./np.sqrt(np.sum(1./slope_uncerts**2)+np.sum(1./slope_uncerts2**2))\n",
    "\n",
    "        # So, this will be the uncertainty in the RA or Dec offset at x= +/- 1. A.K.A., the uncertainty in the slope\n",
    "        # of the line made by tan(zd)*sin(PA) vs RA offset\n",
    "        # or the line tan(zd)*cos(PA) vs Dec offset\n",
    "        # Assuming we know the unshfted position of the object (or there's little covariance if we are fitting for both)\n",
    "        result = total_slope_uncert\n",
    "\n",
    "#         ## version from Bevington page 109 from least-square\n",
    "#         Delta = np.sum(1/pos_var)*np.sum(x_coord**2/pos_var) - np.power(np.sum(x_coord/pos_var), 2)\n",
    "#         result = np.sqrt(np.sum(x_coord**2/pos_var)/Delta)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if your_username == '': # do NOT put your username here, put it in the cell at the top of the notebook.\n",
    "    raise Exception('Please provide your username!  See the top of the notebook.')\n",
    "\n",
    "dbDir = '/home/idies/workspace/lsst_cadence/FBS_1.5/'\n",
    "outDir = f'/home/idies/workspace/Temporary/{your_username}/scratch/MAFOutput/DCR/0807/ResultDBs/'\n",
    "metricDataPath = f'/home/idies/workspace/Temporary/{your_username}/scratch/MAFOutput/DCR/0807/MetricData/'\n",
    "\n",
    "if not os.path.exists(os.path.abspath(outDir)):\n",
    "    os.makedirs(os.path.abspath(outDir))\n",
    "    \n",
    "if not os.path.exists(os.path.abspath(metricDataPath)):\n",
    "    os.makedirs(os.path.abspath(metricDataPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dcr_nham1_ugri_v1.5_10yrs',\n",
       " 'rolling_mod6_sdf_0.20_v1.5_10yrs',\n",
       " 'wfd_depth_scale0.95_noddf_v1.5_10yrs',\n",
       " 'u60_v1.5_10yrs',\n",
       " 'footprint_stuck_rollingv1.5_10yrs']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbRuns = show_opsims(dbDir)\n",
    "dbRuns[0:5] # only show first 5 opsims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Select one OpSim from each family\n",
    "\n",
    "__GTR:__ Where family is indicated by the first part (before the 1st underscore) of the DB file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>runFamil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agnddf_v1.5_10yrs</td>\n",
       "      <td>agnddf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alt_dust_v1.5_10yrs</td>\n",
       "      <td>alt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alt_roll_mod2_dust_sdf_0.20_v1.5_10yrs</td>\n",
       "      <td>alt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline_2snaps_v1.5_10yrs</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline_v1.5_10yrs</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      run  runFamil\n",
       "0                       agnddf_v1.5_10yrs    agnddf\n",
       "1                     alt_dust_v1.5_10yrs       alt\n",
       "2  alt_roll_mod2_dust_sdf_0.20_v1.5_10yrs       alt\n",
       "3              baseline_2snaps_v1.5_10yrs  baseline\n",
       "4                     baseline_v1.5_10yrs  baseline"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbFamil = [run.split('_')[0] for run in dbRuns]\n",
    "dfRuns = pd.DataFrame({'run':dbRuns, \\\n",
    "                       'runFamil':dbFamil}).sort_values(by='runFamil').reset_index(drop=True)\n",
    "dfRuns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>runFamil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agnddf_v1.5_10yrs</td>\n",
       "      <td>agnddf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alt_dust_v1.5_10yrs</td>\n",
       "      <td>alt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline_2snaps_v1.5_10yrs</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bulges_cadence_bs_v1.5_10yrs</td>\n",
       "      <td>bulges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daily_ddf_v1.5_10yrs</td>\n",
       "      <td>daily</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            run  runFamil\n",
       "0             agnddf_v1.5_10yrs    agnddf\n",
       "1           alt_dust_v1.5_10yrs       alt\n",
       "2    baseline_2snaps_v1.5_10yrs  baseline\n",
       "3  bulges_cadence_bs_v1.5_10yrs    bulges\n",
       "4          daily_ddf_v1.5_10yrs     daily"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick on run from each family\n",
    "dfRunPick = dfRuns.drop_duplicates(subset=['runFamil']).reset_index(drop=True)\n",
    "dfRunPick.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__GTR:__ If you want to run all the runs, use \"dfRuns\".  If you are happy just looking at an example from each family, then use \"dfRunPick\" below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two dictionary are returned by the following function, \n",
    "# One (opSimDbs) is a dictionary storing all database objects\n",
    "# Another (resultDbs) is a dictionary consist of the objects directing MAF where to save metric metadata\n",
    "# Both dictionaries are indexed by OpSim run names\n",
    "opSimDbs, resultDbs = connect_dbs(dbDir, outDir, dbRuns=dfRunPick.run.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Declare metrics to for gMag = [19, 21, 23, 25]\n",
    "\n",
    "__GTR:__ The range of g magnitude used for testing spans objects bright enough that DCR is dominated by the floor on the astrometric error and extends to objects so faint that DCR simply cannot be measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healpix slicer using NSIDE=64, approximate resolution 54.967783 arcminutes\n",
      "Healpix slicer using NSIDE=64, approximate resolution 54.967783 arcminutes\n",
      "Healpix slicer using NSIDE=64, approximate resolution 54.967783 arcminutes\n",
      "Healpix slicer using NSIDE=64, approximate resolution 54.967783 arcminutes\n"
     ]
    }
   ],
   "source": [
    "bundleDict = {}\n",
    "for gMag in [19, 21, 23, 25]:\n",
    "    \n",
    "    # declare metric, slicer and sql contraint\n",
    "    DCR_metricG = AGN_DCR('g', src_mag=gMag)\n",
    "    slicer = slicers.HealpixSlicer(nside=64)\n",
    "    constraintG = 'filter = \"g\"'\n",
    "    constraintG += ' and note not like \"DD%\"'\n",
    "    constraintG += ' and proposalId = 1'\n",
    "    \n",
    "    # make a bundle\n",
    "    DCR_mbG = metricBundles.MetricBundle(DCR_metricG, slicer, constraintG)\n",
    "    summaryMetrics = [metrics.MedianMetric(), metrics.MeanMetric(), metrics.RmsMetric()]\n",
    "    DCR_mbG.setSummaryMetrics(summaryMetrics)\n",
    "    \n",
    "    # declare u band metric\n",
    "    DCR_metricU = AGN_DCR('u', src_mag=gMag+0.15)\n",
    "    constraintU = 'filter = \"u\"'\n",
    "    constraintU += ' and note not like \"DD%\"'\n",
    "    constraintU += ' and proposalId = 1'\n",
    "    \n",
    "    # make a bundle\n",
    "    DCR_mbU = metricBundles.MetricBundle(DCR_metricU, slicer, constraintU)\n",
    "    DCR_mbU.setSummaryMetrics(summaryMetrics)\n",
    "\n",
    "    # put into dict\n",
    "    bundleDict[DCR_metricG.metricName] = DCR_mbG\n",
    "    bundleDict[DCR_metricU.metricName] = DCR_mbU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loop over all OpSims in dbDir and run MAF\n",
    "While constructing a metricBundleGroup from a dictionary (the cell below), you will need to provide the path to a directory (`metricDataPath` in the cell below) where you would like to store the metric data (this is **DIFFERENT** than path to the metric data, `outDir`). To construct metricbundles for plotting and further analysis, this path will be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ The code the cell below is deprecated from now the dask version is much faster, but left here for reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # below I am only going to run metrics on the first five opsims\n",
    "# for run in dbRuns[0:3]:\n",
    "#     # must set run name for each opSim to store metric data into\n",
    "#     # separate files\n",
    "#     print(f'Running metrics on: {run}')\n",
    "#     print('*************************************')\n",
    "#     for key in bundleDict:\n",
    "#         bundleDict[key].setRunName(run)\n",
    "        \n",
    "#     metricGroup = metricBundles.MetricBundleGroup(bundleDict,\\\n",
    "#                     opSimDbs[run], metricDataPath, resultDbs[run], verbose=False)\n",
    "#     metricGroup.runAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Run them in parallel with Dask (installing Dask.distributed is required)\n",
    "\n",
    "Install with: \n",
    "```\n",
    "conda install dask distributed -c conda-forge\n",
    "```\n",
    "\n",
    "or:\n",
    "\n",
    "```\n",
    "python -m pip install dask distributed --upgrade\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to run MAF on one opsim which is easily parallelziable. \n",
    "def run_mg(run, bundleDict, dbDir, outDir, metricDataPath):\n",
    "    \"\"\"\n",
    "    Function to run pre-defined MAF metrics on one OpSim. \n",
    "    \n",
    "    Args:\n",
    "        run (str): The OpSim cadence run name.\n",
    "        bundleDict (dict): A dictionary of MAF metrics.\n",
    "        dbDir (str): The path to the OpSim databases.\n",
    "        outDir (str): The path to the resultdb databases.\n",
    "        metricDataPath (str): The path to the actual metric data (.npz files). \n",
    "    \"\"\"\n",
    "    for key in bundleDict:\n",
    "        bundleDict[key].setRunName(run)\n",
    "    \n",
    "    # init connection given run name\n",
    "    opSimDb, resultDb = connect_dbs(dbDir, outDir, dbRuns=[run])\n",
    "    # make a group\n",
    "    metricGroup = metricBundles.MetricBundleGroup(bundleDict, opSimDb[run], metricDataPath, \\\n",
    "                                                  resultDb[run], verbose=False)\n",
    "    metricGroup.runAll()\n",
    "\n",
    "\n",
    "# %%time\n",
    "rt = []\n",
    "\n",
    "# loop over all opsims to evaluate and submite task to dask scheduler\n",
    "for run in dfRunPick.run.values:\n",
    "    r = client.submit(run_mg, run, bundleDict, dbDir, outDir, metricDataPath)\n",
    "    rt.append(r)\n",
    "    \n",
    "# collect result\n",
    "result = client.gather(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
